import torch
import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ø³Ø®Ø© Ø£ØµØºØ± (0.5B) Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø³ÙŠØ±ÙØ±Ø§Øª Render Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ©
model_name = "Qwen/Qwen2.5-0.5B-Instruct"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    torch_dtype=torch.float32, # Ø§Ù„Ù€ CPU ÙŠØ­ØªØ§Ø¬ float32
    low_cpu_mem_usage=True,
    device_map="cpu"
)

def predict(message, history, persona, age_group, job_title):
    system_prompt = f"Ø£Ù†Øª GALAXY AI. Ø´Ø®ØµÙŠØªÙƒ: {persona}. Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¹Ù…Ø±Ù‡ {age_group} ÙˆÙˆØ¸ÙŠÙØªÙ‡ {job_title}."
    
    messages = [{"role": "system", "content": system_prompt}]
    for user_msg, bot_msg in history:
        messages.append({"role": "user", "content": user_msg})
        messages.append({"role": "assistant", "content": bot_msg})
    messages.append({"role": "user", "content": message})

    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    model_inputs = tokenizer([text], return_tensors="pt")
    
    generated_ids = model.generate(**model_inputs, max_new_tokens=256, do_sample=True, temperature=0.7)
    response_ids = [output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]
    return tokenizer.batch_decode(response_ids, skip_special_tokens=True)[0]

# Ø§Ù„ÙˆØ§Ø¬Ù‡Ø©
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.HTML("<h1 style='text-align:center;'>ğŸŒŒ GALAXY AI</h1>")
    with gr.Row():
        persona = gr.Dropdown(["Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø©"], value="Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…", label="Ø§Ù„Ø´Ø®ØµÙŠØ©")
        age = gr.Radio(["Ø·ÙÙ„", "Ø´Ø§Ø¨", "ÙƒØ¨ÙŠØ±"], value="Ø´Ø§Ø¨", label="Ø§Ù„Ø³Ù†")
        job = gr.Textbox(label="Ø§Ù„ÙˆØ¸ÙŠÙØ©", value="Ø·Ø§Ù„Ø¨")
    gr.ChatInterface(fn=predict, additional_inputs=[persona, age, job])

if __name__ == "__main__":
    # Render ÙŠØ­ØªØ§Ø¬ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù„Ù‰ Ø¨ÙˆØ±Øª 10000 Ø£Ùˆ Ø§Ù„Ù…ØªØºÙŠØ± Ø§Ù„Ù…ØªØ§Ø­
    import os
    port = int(os.environ.get("PORT", 10000))
    demo.launch(server_name="0.0.0.0", server_port=port)
